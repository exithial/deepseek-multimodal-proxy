import { GoogleGenerativeAI } from "@google/generative-ai";
import type { ChatMessage } from "../types/openai";
import { logger } from "../utils/logger";
import { processImage, validateFileSize } from "../utils/imageProcessor";
import { generateContextualHash } from "../utils/hashGenerator";
import { cacheService } from "./cacheService";
import { downloader } from "../utils/downloader";
import { getErrorMessage } from "../utils/error";
import type { DetectedContent } from "../middleware/multimodalDetector";

/**
 * Servicio para interactuar con Google Gemini API.
 * Parte de los "Sentidos" en la arquitectura "C√≥rtex Sensorial".
 * Procesa contenido multimedia (im√°genes, audio, video, documentos) y genera
 * descripciones textuales para que DeepSeek pueda comprenderlo.
 */
class GeminiService {
  private client: GoogleGenerativeAI | null = null;
  private model: string;
  private multimodalPrompt: string;
  private apiKey: string | null = null;

  constructor() {
    this.model = process.env.GEMINI_MODEL || "gemini-2.5-flash-lite";
    this.multimodalPrompt =
      process.env.MULTIMODAL_PROMPT ||
      "Analyze this content thoroughly and describe what you see/hear/read in detail. Include all relevant information. Be precise and comprehensive.";
  }

  /**
   * Obtiene el modelo Gemini a usar.
   * Actualmente se usa un modelo √∫nico para todos los tipos de contenido.
   */
  private getModelForContentType(
    _contentType: string,
    _mimeTypeOrExtension: string,
  ): string {
    return this.model;
  }

  /**
   * Obtiene prompt especializado seg√∫n tipo de contenido.
   * Dise√±ado para cubrir los aspectos espec√≠ficos de cada modalidad sensorial.
   */
  private getSpecializedPrompt(
    contentType: string,
    userContext: string = "",
  ): string {
    const basePrompts: Record<string, string> = {
      // Caso 1: Im√°genes (diagramas, interfaces, capturas de error)
      image: `Describe esta imagen con precisi√≥n t√©cnica para que un programador ciego pueda recrearla.

INSTRUCCIONES ESPEC√çFICAS:
1. Si es una INTERFAZ DE USUARIO: Describe layout, elementos, botones, colores, texto visible, jerarqu√≠a visual.
2. Si es un DIAGRAMA DE ARQUITECTURA: Describe componentes, conexiones, flujo de datos, relaciones.
3. Si es una CAPTURA DE ERROR: Describe mensajes de error, n√∫meros de l√≠nea, stack traces, contexto visual.
4. Si contiene TEXTO: Transcribe TODO el texto visible preservando estructura y formato.
5. Incluye COORDENADAS RELATIVAS: Posici√≥n de elementos importantes.
6. S√© LITERAL y PRECISO: No interpretes, solo describe.

${userContext ? `CONTEXTO DEL USUARIO: "${userContext}"\n\nAdapta la descripci√≥n para responder espec√≠ficamente a esta pregunta.` : ""}`,

      // Caso 2: Audio (logs de voz, grabaciones de reuniones)
      audio: `Transcribe y analiza este audio t√©cnico.

INSTRUCCIONES ESPEC√çFICAS:
1. TRANSCRIPCI√ìN LITERAL: Transcribe TODO el audio palabra por palabra.
2. ANOTACIONES DE TONO: Indica [TONO SERIO], [TONO URGENTE], [TONO CONFUSO], etc.
3. PUNTOS CLAVE: Resalta los conceptos t√©cnicos, errores mencionados, decisiones tomadas.
4. ESTRUCTURA TEMPORAL: Marca timestamps aproximados [00:00], [00:30], etc.
5. HABLANTES: Identifica diferentes voces si es posible [HABLANTE 1], [HABLANTE 2].

${userContext ? `CONTEXTO DEL USUARIO: "${userContext}"\n\nEnf√≥cate en los aspectos relevantes para esta pregunta.` : ""}`,

      // Caso 3: Video (grabaciones de pantalla, demos)
      video: `Genera un log cronol√≥gico de lo que ocurre en este video.

INSTRUCCIONES ESPEC√çFICAS:
1. LOG PASO A PASO: Describe eventos en orden temporal.
2. INTERACCIONES: Clics, tecleo, movimientos del cursor.
3. CAMBIOS EN PANTALLA: Aparece/desaparece X, cambia color Y, muestra error Z.
4. AUDIO SIMULT√ÅNEO: Incluye transcripci√≥n del audio sincronizada.
5. MOMENTOS CR√çTICOS: Identifica exactamente cu√°ndo ocurren errores o comportamientos inesperados.

${userContext ? `CONTEXTO DEL USUARIO: "${userContext}"\n\nBusca espec√≠ficamente lo que el usuario pregunta.` : ""}`,

      // Caso 4: Documentos densos/visuales (PDFs, Excel, Notebooks)
      document: `Extrae y estructura la informaci√≥n de este documento.

INSTRUCCIONES ESPEC√çFICAS:
1. TEXTO COMPLETO: Extrae TODO el texto preservando estructura.
2. TABLAS: Convierte a formato Markdown o JSON con headers y datos.
3. GR√ÅFICOS: Describe tipo de gr√°fico, ejes, datos representados, tendencias.
4. ESTRUCTURA JER√ÅRQUICA: T√≠tulos, subt√≠tulos, secciones, listas.
5. DATOS NUM√âRICOS: Extrae n√∫meros, estad√≠sticas, m√©tricas importantes.
6. RELACIONES ESPACIALES: Describe disposici√≥n de elementos en la p√°gina.

${userContext ? `CONTEXTO DEL USUARIO: "${userContext}"\n\nExtrae espec√≠ficamente la informaci√≥n relevante para esta pregunta.` : ""}`,

      // Default
      default: `Analyze this ${contentType} thoroughly and provide the information needed to answer the user's question accurately.

${userContext ? `User's question: "${userContext}"\n\nFocus on providing the specific information needed to answer this question.` : ""}`,
    };

    return basePrompts[contentType] || basePrompts.default;
  }

  /**
   * Carga la API key de las variables de entorno
   */
  private loadApiKey(): string {
    const apiKey = process.env.GEMINI_API_KEY;

    if (!apiKey) {
      logger.warn("‚ö†Ô∏è GEMINI_API_KEY no configurado en .env");
      logger.warn(
        "   Para usar Gemini Multimodal, agrega: GEMINI_API_KEY=tu_api_key",
      );
      logger.warn("   Obt√©n una en: https://aistudio.google.com/app/apikey");
      throw new Error("GEMINI_API_KEY requerido para an√°lisis multimodal");
    }

    return apiKey;
  }

  /**
   * Inicializa el cliente de Gemini
   */
  private ensureClient(): void {
    if (this.client) return;

    this.apiKey = this.loadApiKey();
    this.client = new GoogleGenerativeAI(this.apiKey);
    logger.info("‚úì Cliente Gemini inicializado");
  }

  /**
   * Procesa una fuente de imagen (URL o Base64) a Buffer
   * Con validaci√≥n robusta de Content-Type
   */
  private async processImageSource(
    source: string,
  ): Promise<{ buffer: Buffer; mimeType: string }> {
    // Caso 1: Base64 data URL
    if (source.includes("data:image/")) {
      try {
        const processed = await processImage(source);
        validateFileSize(processed.data);
        return {
          buffer: processed.data,
          mimeType: processed.mimeType || "image/png",
        };
      } catch (error: unknown) {
        logger.error(
          `Error procesando imagen Base64: ${getErrorMessage(error)}`,
        );
        throw new Error(`Imagen Base64 inv√°lida: ${getErrorMessage(error)}`);
      }
    }

    // Caso 2: URL HTTP/HTTPS
    if (source.startsWith("http")) {
      try {
        // Validar tama√±o antes de descargar
        const validation = await downloader.validateFile(source, [
          "image/jpeg",
          "image/jpg",
          "image/png",
          "image/gif",
          "image/webp",
          "image/svg+xml",
          "image/bmp",
          "image/tiff",
        ]);

        if (!validation.valid) {
          throw new Error(`Imagen no v√°lida: ${validation.reason}`);
        }

        logger.info(
          `‚úì Imagen validada: ${(validation.size! / 1024 / 1024).toFixed(2)}MB, ${validation.contentType}`,
        );

        // Intentar descargar como imagen con validaci√≥n estricta
        const buffer = await downloader.downloadImage(source, [
          "image/jpeg",
          "image/jpg",
          "image/png",
          "image/gif",
          "image/webp",
          "image/svg+xml",
          "image/bmp",
          "image/tiff",
        ]);

        // Para URLs, usar PNG como formato universal para Gemini
        return {
          buffer,
          mimeType: "image/png",
        };
      } catch (error: unknown) {
        const errorMsg = getErrorMessage(error);

        // Detectar errores espec√≠ficos de Content-Type
        if (
          errorMsg.includes("Content-Type") ||
          errorMsg.includes("PDF") ||
          errorMsg.includes("HTML")
        ) {
          logger.warn(`‚ö†Ô∏è URL parece no ser una imagen: ${errorMsg}`);

          // Intentar como documento gen√©rico
          try {
            const validation = await downloader.validateFile(source);
            if (!validation.valid) {
              throw new Error(`Documento no v√°lido: ${validation.reason}`);
            }

            const { buffer, contentType } =
              await downloader.downloadFile(source);
            logger.info(
              `‚úÖ URL procesada como documento (${contentType}) en lugar de imagen`,
            );
            return {
              buffer,
              mimeType: contentType,
            };
          } catch (docError: unknown) {
            throw new Error(
              `URL no es imagen v√°lida y fall√≥ como documento: ${getErrorMessage(docError)}`,
            );
          }
        }

        // Otro tipo de error
        throw new Error(`Error descargando imagen: ${errorMsg}`);
      }
    }

    // Caso 3: Ruta local o formato no soportado
    throw new Error(
      `Formato de imagen no soportado: ${source.substring(0, 100)}...`,
    );
  }

  /**
   * Analiza contenido multimodal con Gemini (con cach√© contextual)
   */
  async analyzeContent(
    content: DetectedContent,
    userContext: string = "",
  ): Promise<string> {
    // 1. Verificar si es un PDF - Gemini S√ç soporta PDFs con MIME type application/pdf
    // Mantenemos ambos flujos: local para peque√±os, Gemini para calidad/OCR
    if (
      content.type === "pdf" ||
      (content.extension && content.extension === "pdf")
    ) {
      logger.info(
        `üìÑ PDF detectado - Gemini S√ç soporta PDFs con MIME type application/pdf`,
      );
      // Continuamos con procesamiento Gemini para mejor calidad
    }

    // 2. Procesar contenido seg√∫n tipo
    let processedData: Buffer;
    let mimeType: string;
    let actualContentType = content.type;

    switch (content.type) {
      case "image":
        // TODAS las im√°genes (URLs y Base64) se procesan igual
        const imageResult = await this.processImageSource(content.source);
        processedData = imageResult.buffer;

        // Usar MIME type expl√≠cito del contenido si est√° disponible,
        // de lo contrario usar el detectado por processImageSource
        mimeType = content.mimeType || imageResult.mimeType;

        // Asegurar que el MIME type sea v√°lido para Gemini
        if (!mimeType || mimeType === "application/octet-stream") {
          // Inferir MIME type basado en extensi√≥n o contenido
          if (content.extension) {
            const extToMime: Record<string, string> = {
              ".jpg": "image/jpeg",
              ".jpeg": "image/jpeg",
              ".png": "image/png",
              ".gif": "image/gif",
              ".webp": "image/webp",
              ".bmp": "image/bmp",
              ".svg": "image/svg+xml",
              ".tiff": "image/tiff",
              ".tif": "image/tiff",
            };
            mimeType =
              extToMime[content.extension.toLowerCase()] || "image/png";
          } else {
            mimeType = "image/png"; // Formato universal para Gemini
          }
        }

        // Determinar subtipo de imagen basado en extensi√≥n/contexto
        if (content.extension && ["pdf"].includes(content.extension)) {
          actualContentType = "pdf"; // PDF con im√°genes
        } else if (
          userContext.toLowerCase().includes("diagram") ||
          userContext.toLowerCase().includes("architecture")
        ) {
          actualContentType = "image"; // Enfocar en descripci√≥n t√©cnica
        }
        break;

      case "audio":
        // Descargar audio desde URL o procesar Base64
        if (content.source.startsWith("http")) {
          // Validar tama√±o antes de descargar
          const validation = await downloader.validateFile(content.source);
          if (!validation.valid) {
            throw new Error(`Archivo de audio no v√°lido: ${validation.reason}`);
          }

          logger.info(
            `‚úì Audio validado: ${(validation.size! / 1024 / 1024).toFixed(2)}MB, ${validation.contentType}`,
          );

          const { buffer, contentType } = await downloader.downloadFile(
            content.source,
          );
          processedData = buffer;
          mimeType = contentType;
        } else if (content.source.includes("data:audio/")) {
          // Extraer MIME type de data URL
          const dataUrlMatch = content.source.match(
            /^data:([^;]+)(?:;[^;]+)?;base64,(.+)$/,
          );
          if (dataUrlMatch) {
            const [, extractedMimeType, base64Data] = dataUrlMatch;
            processedData = Buffer.from(base64Data, "base64");
            mimeType = extractedMimeType || content.mimeType || "audio/mpeg";
          } else {
            const base64Data = content.source.split(",")[1];
            processedData = Buffer.from(base64Data, "base64");
            mimeType = content.mimeType || "audio/mpeg";
          }
        } else {
          processedData = Buffer.from(
            `[AUDIO CONTENT: ${content.source.substring(0, 100)}...]`,
          );
          mimeType = content.mimeType || "audio/mpeg";
        }
        break;

      case "video":
        // Descargar video desde URL o procesar Base64
        if (content.source.startsWith("http")) {
          // Validar tama√±o antes de descargar
          const validation = await downloader.validateFile(content.source);
          if (!validation.valid) {
            throw new Error(`Archivo de video no v√°lido: ${validation.reason}`);
          }

          logger.info(
            `‚úì Video validado: ${(validation.size! / 1024 / 1024).toFixed(2)}MB, ${validation.contentType}`,
          );

          const { buffer, contentType } = await downloader.downloadFile(
            content.source,
          );
          processedData = buffer;
          mimeType = contentType;
        } else if (content.source.includes("data:video/")) {
          // Extraer MIME type de data URL
          const dataUrlMatch = content.source.match(
            /^data:([^;]+)(?:;[^;]+)?;base64,(.+)$/,
          );
          if (dataUrlMatch) {
            const [, extractedMimeType, base64Data] = dataUrlMatch;
            processedData = Buffer.from(base64Data, "base64");
            mimeType = extractedMimeType || content.mimeType || "video/mp4";
          } else {
            const base64Data = content.source.split(",")[1];
            processedData = Buffer.from(base64Data, "base64");
            mimeType = content.mimeType || "video/mp4";
          }
        } else {
          processedData = Buffer.from(
            `[VIDEO CONTENT: ${content.source.substring(0, 100)}...]`,
          );
          mimeType = content.mimeType || "video/mp4";
        }
        break;

      case "pdf":
      case "text":
        // C√≥digo y texto van directo a DeepSeek,  pero por si acaso
        // Nota: Ahora usamos `type` normalizado OpenCode
        processedData = Buffer.from(content.source);
        mimeType = "text/plain";
        actualContentType = "text"; // Usar prompt de documentos
        break;

      default:
        throw new Error(`Tipo de contenido no soportado: ${content.type}`);
    }

    // 2. Calcular hash contextual
    const hash = generateContextualHash(processedData, userContext);
    logger.debug(`üîç Hash contextual: ${hash.substring(0, 16)}...`);

    // 3. Consultar cach√©
    const cached = await cacheService.get(hash);
    if (cached) {
      logger.info(
        `‚úì Cache HIT: ${hash.substring(0, 8)}... (${cached.hits} hits)`,
      );
      await cacheService.incrementHits(hash);
      return cached.description;
    }

    logger.info(`‚úó Cache MISS: ${hash.substring(0, 8)}...`);

    // 4. Analizar con Gemini
    this.ensureClient();
    const description = await this.analyzeWithGemini(
      processedData,
      mimeType,
      actualContentType,
      userContext,
    );

    // 5. Guardar en cach√©
    await cacheService.set(hash, description, this.model);

    return description;
  }

  /**
   * Analiza contenido directamente con Gemini
   * Con manejo robusto de filtros de seguridad
   */
  private async analyzeWithGemini(
    contentData: Buffer,
    mimeType: string,
    contentType: string,
    userContext: string = "",
  ): Promise<string> {
    if (!this.client) {
      throw new Error("Cliente Gemini no inicializado");
    }

    try {
      logger.info(`üîÑ Analizando ${contentType} con ${this.model}...`);
      const startTime = Date.now();

      const model = this.client.getGenerativeModel({
        model: this.model,
        // Configuraci√≥n de seguridad para contenido t√©cnico.
        generationConfig: {
          temperature: 0.1, // M√°s determin√≠stico para an√°lisis t√©cnico
          topP: 0.8,
          topK: 40,
        },
      });

      // Usar prompt especializado seg√∫n tipo de contenido
      const prompt = this.getSpecializedPrompt(contentType, userContext);

      // Convertir contenido a formato Gemini
      const contentPart = {
        inlineData: {
          data: contentData.toString("base64"),
          mimeType: mimeType,
        },
      };

      const result = await model.generateContent([prompt, contentPart]);
      const response = result.response;

      // Verificar si la respuesta fue bloqueada por seguridad
      if (response.promptFeedback?.blockReason) {
        const blockReason = response.promptFeedback.blockReason;
        logger.warn(`‚ö†Ô∏è Gemini bloque√≥ el contenido: ${blockReason}`);

        // Devolver mensaje informativo para DeepSeek
        return this.getSafetyBlockedMessage(
          contentType,
          blockReason,
          userContext,
        );
      }

      const text = response.text();

      const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);
      logger.info(
        `‚úì ${contentType} analizado en ${elapsed}s con ${this.model}`,
      );

      return text;
    } catch (error: any) {
      // Detectar errores espec√≠ficos de seguridad de Gemini
      const errorMessage = error.message || "";

      if (
        errorMessage.includes("SAFETY") ||
        errorMessage.includes("blocked") ||
        errorMessage.includes("unsafe") ||
        errorMessage.includes("content policy")
      ) {
        logger.warn(
          `üîí Gemini bloque√≥ el contenido por seguridad: ${errorMessage}`,
        );

        // Devolver mensaje informativo en lugar de fallar
        return this.getSafetyBlockedMessage(
          contentType,
          "SAFETY_FILTER",
          userContext,
        );
      }

      // Otros errores de API
      logger.error(`‚úó Error en Gemini API (${contentType}):`, errorMessage);
      throw new Error(`Gemini Multimodal fall√≥: ${errorMessage}`);
    }
  }

  /**
   * Genera mensaje informativo cuando Gemini bloquea contenido por seguridad
   */
  private getSafetyBlockedMessage(
    contentType: string,
    blockReason: string,
    userContext: string = "",
  ): string {
    const reasons: Record<string, string> = {
      SAFETY: "restricciones de seguridad",
      BLOCKED: "filtros de contenido",
      UNSAFE: "contenido considerado inseguro",
      SAFETY_FILTER: "filtros de seguridad",
      HARM_CATEGORY_HARASSMENT: "posible acoso",
      HARM_CATEGORY_HATE_SPEECH: "posible discurso de odio",
      HARM_CATEGORY_SEXUALLY_EXPLICIT: "contenido sexualmente expl√≠cito",
      HARM_CATEGORY_DANGEROUS_CONTENT: "contenido peligroso",
    };

    const reasonText = reasons[blockReason] || "restricciones de seguridad";

    return `[SISTEMA: El ${contentType} no pudo ser analizado por ${reasonText}. 

Contexto del usuario: "${userContext || "No proporcionado"}"

Para continuar:
1. Describe verbalmente el contenido del ${contentType}
2. Explica qu√© informaci√≥n necesitas extraer
3. Si es un diagrama/error t√©cnico, describe los elementos clave
4. Si contiene texto, transcr√≠belo manualmente

El asistente podr√° ayudarte con la descripci√≥n proporcionada.]`;
  }

  /**
   * M√©todo de compatibilidad para im√°genes (backward compatibility)
   */
  async analyzeImage(
    imageSource: string,
    userContext: string = "",
  ): Promise<string> {
    return this.analyzeContent(
      {
        source: imageSource,
        type: "image",
        messageIndex: 0,
        internalType: "image",
      },
      userContext,
    );
  }

  async generateDirectResponse(messages: ChatMessage[]): Promise<string> {
    this.ensureClient();

    const geminiMessages = messages.map((msg) => ({
      role: msg.role === "assistant" ? "model" : "user",
      parts: [
        {
          text:
            typeof msg.content === "string"
              ? msg.content
              : JSON.stringify(msg.content ?? ""),
        },
      ],
    }));

    const model = this.client!.getGenerativeModel({
      model: this.model,
    });

    const lastMessage = geminiMessages[geminiMessages.length - 1];
    if (!lastMessage) {
      throw new Error("No hay mensajes para procesar con Gemini");
    }

    try {
      const chat = model.startChat({
        history: geminiMessages.slice(0, -1),
      });
      const result = await chat.sendMessage(lastMessage.parts);
      return result.response.text();
    } catch (error: any) {
      logger.error("Error en generacion directa Gemini:", error);
      throw new Error(`Gemini error: ${error.message}`);
    }
  }
}

export const geminiService = new GeminiService();
