# DeepSeek Vision Proxy (Gemini + Ollama Edition)

Proxy HTTP OpenAI-compatible que a√±ade capacidades de visi√≥n a DeepSeek utilizando **Google Gemini 2.5 Flash** para el an√°lisis de im√°genes.

## üéØ Caracter√≠sticas

- ‚úÖ **Visi√≥n por Gemini 2.5 Flash**: An√°lisis de im√°genes ultra-r√°pido y preciso.
- ‚úÖ **Prompting Contextual**: El an√°lisis de la imagen se adapta inteligentemente a la pregunta del usuario.
- ‚úÖ **Detecci√≥n multiformato**: Soporta Base64, URLs y archivos locales.
- ‚úÖ **Cach√© Inteligente**: Hash contextual SHA-256 para evitar llamadas repetidas a la API (TTL configurable).
- ‚úÖ **Streaming SSE**: Respuestas en tiempo real compatibles con clientes OpenAI.
- ‚úÖ **Zero Overhead**: Passthrough directo si no hay im√°genes.

## üì¶ Requisitos

- **Node.js** >= 18.0.0
- **DeepSeek API Key** (opcional, para modelos en la nube)
- **Google Gemini API Key** (para visi√≥n)

## üöÄ Instalaci√≥n R√°pida

### Opci√≥n 1: Script Autom√°tico (Recomendado)

```bash
cd /home/exithial/Proyectos/deepseek-vision-proxy
./setup-deepseek-proxy.sh
```

Esto configurar√° todo autom√°ticamente:

- Detendr√° procesos existentes (sin interrumpir OpenCode)
- Recompilar√° el proyecto
- Crear√° servicio systemd con inicio autom√°tico
- Verificar√° que todo funcione correctamente

### Opci√≥n 2: Instalaci√≥n Manual

```bash
# 1. Instalar dependencias
npm install

# 2. Compilar
npm run build

# 3. Configurar variables de entorno
cp .env.example .env
# Editar .env con tus API keys

# 4. Iniciar
npm run dev  # Modo desarrollo
# o
npm start    # Modo producci√≥n
```

### Scripts de Gesti√≥n Disponibles:

- `./setup-deepseek-proxy.sh` - Configuraci√≥n completa
- `./check-proxy-status.sh` - Verificaci√≥n de estado
- `./uninstall-proxy.sh` - Desinstalaci√≥n completa
- `./test-proxy-complete.js` - Pruebas integrales

## ‚öôÔ∏è Configuraci√≥n

Crea o edita el archivo `.env`:

```bash
# Servidor
PORT=7777
LOG_LEVEL=info

# Gemini Vision
GEMINI_API_KEY=tu_api_key_de_google_aistudio

# Configuraci√≥n del Modelo
GEMINI_MODEL=gemini-2.5-flash

# DeepSeek API (opcional, para modelos en la nube)
DEEPSEEK_API_KEY=sk-tu-api-key-aqui



# Cach√© (Recomendado)
CACHE_ENABLED=true
CACHE_TTL_DAYS=7
```

## üîå Integraci√≥n con OpenCode

### Configuraci√≥n Simplificada (Recomendada)

Agrega esto a tu `~/.config/opencode/opencode.json`:

```json
{
  "provider": {
    "deepseek-proxy": {
      "name": "DeepSeek + Ollama con Visi√≥n (Proxy)",
      "npm": "@ai-sdk/openai-compatible",
      "options": {
        "baseURL": "http://localhost:7777/v1",
        "apiKey": "not-needed"
      },
      "models": {
        "vision-dsk-chat": {
          "name": "vision-dsk-chat",
          "limit": {
            "context": 128000,
            "output": 8000
          },
          "modalities": {
            "input": ["text", "image"],
            "output": ["text"]
          }
        },
        },
        "vision-dsk-reasoner": {
          "name": "vision-dsk-reasoner",
          "limit": {
            "context": 128000,
            "output": 64000
          },
          "modalities": {
            "input": ["text", "image"],
            "output": ["text"]
          }
        }
      }
    }
  }
}
```

**Nota:** Esta configuraci√≥n incluye solo modelos principales con visi√≥n habilitada para todos.

## üîÑ Flujo de Trabajo

1. **Recepci√≥n**: El proxy recibe el request en puerto 7777.
2. **Detecci√≥n**: Analiza si el √∫ltimo mensaje contiene im√°genes (URL o Base64).
3. **Procesamiento**:
   - **Sin im√°genes**: Reenv√≠a directamente a DeepSeek (passthrough).
   - **Con im√°genes**:
     1. Calcula hash √∫nico de la imagen + contexto de la pregunta.
     2. Consulta cach√© local.
     3. Si no est√° en cach√©, env√≠a a **Gemini Flash** con un prompt adaptativo.
     4. Reemplaza la imagen en el prompt original con la descripci√≥n textual generada.
4. **Respuesta**: Env√≠a el prompt enriquecido a DeepSeek y devuelve la respuesta en stream.

## üõ†Ô∏è Soporte para Herramientas (Tools)

El proxy soporta completamente las herramientas de OpenAI (`tools` y `tool_choice`):

- **Forward transparente**: Las herramientas se reenv√≠an directamente a DeepSeek sin modificaci√≥n.
- **Compatible con im√°genes**: Las herramientas funcionan incluso cuando hay im√°genes en el mensaje (despu√©s de ser procesadas).
- **Streaming**: Soporta herramientas tanto en modo streaming como no-streaming.

### Ejemplo de uso con herramientas:

```json
{
  "model": "vision-dsk-chat",
  "messages": [...],
  "tools": [...],
  "tool_choice": "auto"
}
```

## üìä Endpoints

| Endpoint               | M√©todo | Descripci√≥n                       |
| ---------------------- | ------ | --------------------------------- |
| `/v1/chat/completions` | POST   | Chat standard (compatible OpenAI) |
| `/v1/cache/stats`      | GET    | Estad√≠sticas de uso del cach√©     |
| `/v1/models`           | GET    | Lista de modelos                  |
| `/health`              | GET    | Estado del servicio               |

## üõ†Ô∏è Comandos √ötiles

```bash
# Ver estado del servicio
systemctl --user status deepseek-proxy

# Ver logs en tiempo real
journalctl --user -u deepseek-proxy -f

# Reiniciar servicio
systemctl --user restart deepseek-proxy

# Ver estad√≠sticas de cach√©
curl http://localhost:7777/v1/cache/stats
```

## üìù Licencia

MIT
