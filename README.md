# DeepSeek Multimodal Proxy (Gemini Edition)

![License](https://img.shields.io/github/license/exithial/deepseek-multimodal-proxy?style=flat-square)
![Version](https://img.shields.io/github/package-json/v/exithial/deepseek-multimodal-proxy?style=flat-square)
![Node Version](https://img.shields.io/node/v/deepseek-multimodal-proxy?style=flat-square)

Proxy HTTP OpenAI-compatible que implementa **arquitectura "C√≥rtex Sensorial"** para a√±adir capacidades multimodales a DeepSeek utilizando **Google Gemini 2.5 Flash Lite** como sistema de percepci√≥n.

## üéØ Arquitectura "C√≥rtex Sensorial"

### **Visi√≥n Conceptual**

- **DeepSeek = Cerebro**: L√≥gica, c√≥digo, razonamiento puro
- **Gemini 2.5 Flash Lite = Sentidos**: Percepci√≥n multimodal (im√°genes, audio, video, documentos, PDFs)
- **Proxy = C√≥rtex**: Routing inteligente seg√∫n especialidad cognitiva

### **Caracter√≠sticas Principales**

- ‚úÖ **Routing Inteligente Autom√°tico**: Detecta 8 tipos de contenido y decide routing √≥ptimo
- ‚úÖ **Multimodalidad Completa**: Im√°genes, audio, video, PDFs, documentos, c√≥digo, texto
- ‚úÖ **Modo Directo**: Usa `gemini-direct` para bypassing DeepSeek y obtener respuestas ultra-r√°pidas directamente de Gemini
- ‚úÖ **Procesamiento H√≠brido de PDFs**: Local (<1MB) para velocidad o Gemini (>1MB) para calidad/OCR
- ‚úÖ **Descarga Autom√°tica con Validaci√≥n**: URLs con validaci√≥n Content-Type real y l√≠mite de 50MB
- ‚úÖ **Cach√© Contextual SHA-256**: Hash √∫nico por contenido + pregunta (Evita re-procesamiento)
- ‚úÖ **Streaming SSE**: Soporte nativo para respuestas en tiempo real (compatible con OpenCode)
- ‚úÖ **Optimizado para OpenCode**: Mapeo transparente de modalidades `text`, `image`, `audio`, `video`, `pdf`

## üì¶ Requisitos

- **Node.js** >= 18.0.0
- **DeepSeek API Key** (Para razonamiento/texto)
- **Google Gemini API Key** (Para percepci√≥n multimodal)

## üöÄ Instalaci√≥n R√°pida

### Opci√≥n 1: Script Autom√°tico (Recomendado)

```bash
git clone https://github.com/exithial/deepseek-multimodal-proxy.git
cd deepseek-multimodal-proxy
./scripts/setup.sh
```

Esto configurar√° todo autom√°ticamente:

- Recompila el proyecto con TypeScript
- Instala el servicio systemd `deepseek-proxy`
- Verifica la disponibilidad del servicio y los modelos

### Opci√≥n 2: Instalaci√≥n Manual

```bash
# 1. Instalar dependencias
npm install

# 2. Compilar
npm run build

# 3. Configurar .env
cp .env.example .env # Y editar con tus claves

# 4. Iniciar servicio (v√≠a script unificado)
./scripts/manage.sh start
```

## üß™ Pruebas

```bash
npm run test:master
npm run test:claude
npm run test:all
```

## üîå Integraci√≥n con OpenCode

### Configuraci√≥n Multimodal Completa

Agrega esto a tu `~/.config/opencode/opencode.json`:

```json
{
  "provider": {
    "deepseek-multimodal": {
      "name": "DeepSeek Multimodal (Proxy Inteligente)",
      "npm": "@ai-sdk/openai-compatible",
      "options": {
        "baseURL": "http://localhost:7777/v1",
        "apiKey": "not-needed"
      },
      "models": {
        "deepseek-multimodal-chat": {
          "name": "deepseek-multimodal-chat",
          "cost": { "input": 0.5, "output": 1.5 },
          "limit": { "context": 100000, "output": 8000 },
          "modalities": {
            "input": ["text", "image", "audio", "video", "pdf"],
            "output": ["text"]
          }
        },
        "deepseek-multimodal-reasoner": {
          "name": "deepseek-multimodal-reasoner",
          "cost": { "input": 1.0, "output": 3.0 },
          "limit": { "context": 100000, "output": 64000 },
          "modalities": {
            "input": ["text", "image", "audio", "video", "pdf"],
            "output": ["text"]
          }
        },
        "gemini-direct": {
          "name": "gemini-direct",
          "cost": { "input": 0.0, "output": 0.0 },
          "limit": { "context": 1000000, "output": 8192 },
          "modalities": {
            "input": ["text", "image", "audio", "video", "pdf"],
            "output": ["text"]
          }
        }
      }
    }
  }
}
```

## ü§ñ Integraci√≥n con Claude Code (Anthropic)

Configura el CLI para usar el proxy como backend Anthropic:

```bash
export ANTHROPIC_BASE_URL="http://localhost:7777"
```

Tambien puedes configurar `.claude/settings.json`:

```json
{
  "env": {
    "ANTHROPIC_AUTH_TOKEN": "test",
    "ANTHROPIC_API_KEY": "test",
    "ANTHROPIC_BASE_URL": "http://localhost:7777",
    "ANTHROPIC_MODEL": "sonnet",
    "ANTHROPIC_DEFAULT_OPUS_MODEL": "opus",
    "ANTHROPIC_DEFAULT_SONNET_MODEL": "sonnet",
    "ANTHROPIC_DEFAULT_HAIKU_MODEL": "haiku",
    "CLAUDE_CODE_SUBAGENT_MODEL": "sonnet",
    "ENABLE_EXPERIMENTAL_MCP_CLI": "true"
  },
  "model": "sonnet"
}
```

Modelos disponibles para Claude Code:

- `haiku` ‚Üí **gemini-direct** (r√°pido/econ√≥mico, bypass total de DeepSeek)
- `sonnet` ‚Üí **deepseek-multimodal-chat** (routing inteligente por contenido)
- `opus` ‚Üí **deepseek-multimodal-reasoner** (routing inteligente por contenido)

### **Routing Inteligente por Modelo**

El proxy implementa routing autom√°tico basado en el modelo:

- **Haiku**: Todo va a `gemini-direct` para m√°xima velocidad
- **Sonnet/Opus**: Routing inteligente seg√∫n tipo de contenido:
  - **Texto/c√≥digo** ‚Üí DeepSeek directo
  - **Im√°genes/audio/video** ‚Üí Gemini ‚Üí DeepSeek
  - **PDFs peque√±os** ‚Üí Procesamiento local ‚Üí DeepSeek
  - **PDFs grandes** ‚Üí Gemini ‚Üí DeepSeek

## üîÑ Flujo de Trabajo "C√≥rtex Sensorial"

### **Matriz de Routing Validada**

| Contenido          | Ejemplos                  | Routing                  | Raz√≥n                                |
| :----------------- | :------------------------ | :----------------------- | :----------------------------------- |
| **Texto / C√≥digo** | `.js`, `.py`, `.md`       | üöÄ **DeepSeek directo**  | M√°xima precisi√≥n l√≥gica y sint√°ctica |
| **Im√°genes**       | `.jpg`, `.png`, Base64    | üëÅÔ∏è **Gemini ‚Üí DeepSeek** | OCR superior y descripci√≥n visual    |
| **Audio**          | `.mp3`, `.wav`, `.m4a`    | üëÅÔ∏è **Gemini ‚Üí DeepSeek** | Transcripci√≥n y an√°lisis de tono     |
| **Video**          | `.mp4`, `.mov`, `.webm`   | üëÅÔ∏è **Gemini ‚Üí DeepSeek** | An√°lisis temporal de frames y audio  |
| **PDF (< 1MB)**    | `invoice.pdf`             | üè† **Local ‚Üí DeepSeek**  | Privacidad y velocidad (pdf-parse)   |
| **PDF (> 1MB)**    | `manual.pdf`              | üëÅÔ∏è **Gemini ‚Üí DeepSeek** | Mejor manejo de contexto y tablas    |
| **Docs**           | `.docx`, `.xlsx`, `.pptx` | üëÅÔ∏è **Gemini ‚Üí DeepSeek** | Extracci√≥n estructural compleja      |

### **Proceso Detallado**

1. **Recepci√≥n**: Request en puerto 7777 (compatible OpenAI)
2. **Detecci√≥n**: Analiza contenido por extensi√≥n/MIME type (m√∫ltiples categor√≠as)
3. **Routing Inteligente**: Decide seg√∫n matriz anterior
4. **Procesamiento** (seg√∫n tipo):

   **Para PDFs (Routing Inteligente Basado en Tama√±o):**
   - **Descarga**: URL o Base64 con validaci√≥n de tama√±o (HEAD request para URLs)
   - **Detecci√≥n de tama√±o**: Autom√°tica para decidir routing √≥ptimo
   - **Routing inteligente**:
     - **PDFs peque√±os (< 1MB por defecto)**: Procesamiento local (configurable)
     - **PDFs grandes o complejos**: Gemini (mejor calidad, soporta OCR)
   - **Configurable**: Variables `PDF_LOCAL_PROCESSING` y `PDF_LOCAL_MAX_SIZE_MB`
   - **Extracci√≥n Doble Local**: pdf2json (estructurado) ‚Üí pdf-parse (fallback)
   - **An√°lisis Gemini**: Mejor comprensi√≥n de estructura, tablas, OCR, multilenguaje
   - **Fallback autom√°tico**: Si procesamiento local falla ‚Üí Gemini autom√°ticamente
   - **Cache**: SHA-256(content + pregunta)
   - **Env√≠o**: Texto procesado por Gemini o extra√≠do localmente a DeepSeek

   **Para Otros Formatos (Gemini):**
   - **Descarga con Validaci√≥n**: URLs con Content-Type real
   - **Hash Contextual**: SHA-256(content + user question)
   - **Cach√©**: Consulta local para evitar llamadas repetidas
   - **An√°lisis Especializado**: Prompt adaptado al tipo de contenido
   - **Transformaci√≥n**: Contenido f√≠sico ‚Üí Texto estructurado

5. **Respuesta**: DeepSeek genera respuesta final (streaming o batch)

### **Configuraci√≥n de Procesamiento de PDFs**

El sistema implementa **routing inteligente basado en tama√±o** para PDFs:

#### **Variables de Entorno (.env):**

```bash
# Procesamiento de PDFs
PDF_LOCAL_PROCESSING=true          # Habilitar procesamiento local para PDFs peque√±os
PDF_LOCAL_MAX_SIZE_MB=1            # Tama√±o m√°ximo para procesamiento local (1MB por defecto)
```

#### **Ventajas de Cada Opci√≥n:**

**Procesamiento Local (PDFs peque√±os):**

- ‚úÖ **Sin costo de API** Gemini
- ‚úÖ **M√°s r√°pido** para PDFs de texto simple
- ‚úÖ **Privacidad**: Datos no salen del servidor

**Gemini (PDFs grandes/complejos):**

- ‚úÖ **Mejor calidad**: Entiende estructura, tablas, gr√°ficos
- ‚úÖ **OCR integrado**: Soporta PDFs escaneados/im√°genes
- ‚úÖ **Multilenguaje**: Mejor soporte para idiomas diversos

## üõ°Ô∏è Micro-Optimizaciones Cr√≠ticas

### **Validaci√≥n Content-Type Real**

```typescript
// No conf√≠a en extensiones, valida headers HTTP reales
if (contentType.includes("text/html")) {
  throw new Error("URL devuelve HTML, no un tipo de archivo v√°lido");
}
```

### **Manejo Filtros Seguridad Gemini**

```typescript
// Fallback informativo, no error silencioso
return `[SISTEMA: Contenido bloqueado por seguridad. Describe verbalmente...]`;
```

### **Cach√© Contextual SHA-256**

```typescript
// Hash √∫nico por combinaci√≥n contenido + pregunta
const cacheKey = sha256(content + userQuestion);
```

## ÔøΩÔ∏è Soporte para Herramientas (Tools)

El proxy soporta completamente las herramientas de OpenAI (`tools` y `tool_choice`):

- **Forward transparente**: Tools reenviadas directamente a DeepSeek
- **Compatible con multimodalidad**: Funciona despu√©s del procesamiento Gemini

## ÔøΩüìä Endpoints & M√©tricas

| Endpoint               | M√©todo | Descripci√≥n                         |
| ---------------------- | ------ | ----------------------------------- |
| `/v1/chat/completions` | POST   | Chat multimodal (compatible OpenAI) |
| `/v1/cache/stats`      | GET    | Estad√≠sticas de cach√© contextual    |
| `/v1/models`           | GET    | Lista de modelos multimodales       |
| `/health`              | GET    | Estado del servicio + versi√≥n       |

### **M√©tricas T√©cnicas**

- **Tama√±o m√°ximo**: **50MB por archivo** (l√≠mite oficial de Gemini API)
- **Validaci√≥n previa**: HEAD requests detectan archivos > 50MB antes de descargar
- **Timeout descarga**: **120 segundos** para archivos grandes
- **Cach√© TTL**: 7 d√≠as (configurable)
- **Formatos soportados**:
  - **Im√°genes**: JPEG, PNG, GIF, WebP, BMP, TIFF, SVG
  - **Audio**: MP3, WAV
  - **Video**: MP4, MOV
  - **Documentos**: PDF, Excel, Word, PowerPoint

## üß™ Pruebas y Gesti√≥n

Usa el script unificado `manage.sh` para controlar el proxy:

```bash
./scripts/manage.sh start      # Iniciar servicio
./scripts/manage.sh stop       # Detener servicio
./scripts/manage.sh status     # Ver estado y salud de la API
./scripts/manage.sh logs       # Ver logs en tiempo real
./scripts/manage.sh uninstall  # Eliminar el servicio del sistema
```

Para pruebas r√°pidas sin instalaci√≥n:

```bash
./scripts/run-local.sh
```

**Verificaci√≥n Integral:**

```bash
node test/test-master.js
```

## ‚úÖ Estado Actual - Versi√≥n 1.5.0

- ‚úÖ **Arquitectura "C√≥rtex Sensorial"** completa
- ‚úÖ **Routing inteligente por modelo** (haiku ‚Üí gemini-direct, sonnet/opus ‚Üí deepseek-routing)
- ‚úÖ **Soporte completo Claude Code** con tipos de contenido extendidos (input_audio, clipboard, file)
- ‚úÖ **Descarga con validaci√≥n robusta** (Content-Type real)
- ‚úÖ **Cach√© contextual SHA-256** eficiente
- ‚úÖ **Audio/Video soportados** (MP3/MP4 testeados)
- ‚úÖ **PDFs soportados** v√≠a Gemini o localmente

## ‚òï Soporte y Caf√©

Si encuentras √∫til este proxy y quieres apoyar el desarrollo de m√°s herramientas de c√≥digo abierto, ¬°puedes invitarme a un caf√©!

[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-Donate-orange?style=for-the-badge&logo=buy-me-a-coffee)](https://buymeacoffee.com/exithial)

## üìù Licencia

MIT
