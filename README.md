# DeepSeek Vision Proxy (Gemini Edition)

Proxy HTTP OpenAI-compatible que a√±ade capacidades de visi√≥n a DeepSeek utilizando **Google Gemini 2.5 Flash** para el an√°lisis de im√°genes.

## üéØ Caracter√≠sticas

- ‚úÖ **Visi√≥n por Gemini 2.5 Flash**: An√°lisis de im√°genes ultra-r√°pido y preciso.
- ‚úÖ **Prompting Contextual**: El an√°lisis de la imagen se adapta inteligentemente a la pregunta del usuario.
- ‚úÖ **Detecci√≥n multiformato**: Soporta Base64, URLs y archivos locales.
- ‚úÖ **Cach√© Inteligente**: Hash contextual SHA-256 para evitar llamadas repetidas a la API (TTL configurable).
- ‚úÖ **Streaming SSE**: Respuestas en tiempo real compatibles con clientes OpenAI.
- ‚úÖ **Zero Overhead**: Passthrough directo si no hay im√°genes.

## üì¶ Requisitos

- **Node.js** >= 18.0.0
- **DeepSeek API Key**
- **Google Gemini API Key**

## üöÄ Instalaci√≥n R√°pida

```bash
cd /home/exithial/Proyectos/deepseek-vision-proxy
./install.sh
```

Esto instalar√° dependencias, compilar√° el proyecto y configurar√° el servicio systemd.

## ‚öôÔ∏è Configuraci√≥n

Crea o edita el archivo `.env`:

```bash
# Servidor
PORT=7777
LOG_LEVEL=info

# Gemini Vision
GEMINI_API_KEY=tu_api_key_de_google_aistudio

# Configuraci√≥n del Modelo
GEMINI_MODEL=gemini-2.5-flash

# DeepSeek API
DEEPSEEK_API_KEY=sk-tu-api-key-aqui

# Cach√© (Recomendado)
CACHE_ENABLED=true
CACHE_TTL_DAYS=7
```

## üîå Integraci√≥n con OpenCode

Agrega esto a tu `~/.config/opencode/opencode.json`:

```json
{
  "provider": {
    "deepseek": {
      "name": "DeepSeek Vision (Gemini Proxy)",
      "npm": "@ai-sdk/openai-compatible",
      "options": {
        "baseURL": "http://localhost:7777/v1",
        "apiKey": "not-needed"
      },
      "models": {
        "vision-dsk-chat": {
          "name": "vision-dsk-chat",
          "limit": {
            "context": 100000,
            "output": 4000
          },
          "modalities": {
            "input": ["text", "image"],
            "output": ["text"]
          }
        },
        "vision-dsk-reasoner": {
          "name": "vision-dsk-reasoner",
          "limit": {
            "context": 100000,
            "output": 16000
          },
          "modalities": {
            "input": ["text", "image"],
            "output": ["text"]
          }
        },
        "deepseek-vision-chat": {
          "name": "deepseek-vision-chat",
          "limit": {
            "context": 100000,
            "output": 4000
          },
          "modalities": {
            "input": ["text", "image"],
            "output": ["text"]
          }
        },
        "deepseek-vision-reasoner": {
          "name": "deepseek-vision-reasoner",
          "limit": {
            "context": 100000,
            "output": 16000
          },
          "modalities": {
            "input": ["text", "image"],
            "output": ["text"]
          }
        }
      }
    }
  }
}
```

## üîÑ Flujo de Trabajo

1. **Recepci√≥n**: El proxy recibe el request en puerto 7777.
2. **Detecci√≥n**: Analiza si el √∫ltimo mensaje contiene im√°genes (URL o Base64).
3. **Procesamiento**:
   - **Sin im√°genes**: Reenv√≠a directamente a DeepSeek (passthrough).
   - **Con im√°genes**:
     1. Calcula hash √∫nico de la imagen + contexto de la pregunta.
     2. Consulta cach√© local.
     3. Si no est√° en cach√©, env√≠a a **Gemini Flash** con un prompt adaptativo.
     4. Reemplaza la imagen en el prompt original con la descripci√≥n textual generada.
4. **Respuesta**: Env√≠a el prompt enriquecido a DeepSeek y devuelve la respuesta en stream.

## üõ†Ô∏è Soporte para Herramientas (Tools)

El proxy soporta completamente las herramientas de OpenAI (`tools` y `tool_choice`):

- **Forward transparente**: Las herramientas se reenv√≠an directamente a DeepSeek sin modificaci√≥n.
- **Compatible con im√°genes**: Las herramientas funcionan incluso cuando hay im√°genes en el mensaje (despu√©s de ser procesadas).
- **Streaming**: Soporta herramientas tanto en modo streaming como no-streaming.

### Ejemplo de uso con herramientas:
```json
{
  "model": "vision-dsk-chat",
  "messages": [...],
  "tools": [...],
  "tool_choice": "auto"
}
```

## üìä Endpoints

| Endpoint | M√©todo | Descripci√≥n |
|----------|--------|-------------|
| `/v1/chat/completions` | POST | Chat standard (compatible OpenAI) |
| `/v1/cache/stats` | GET | Estad√≠sticas de uso del cach√© |
| `/v1/models` | GET | Lista de modelos |
| `/health` | GET | Estado del servicio |

## üõ†Ô∏è Comandos √ötiles

```bash
# Ver estado del servicio
systemctl --user status deepseek-proxy

# Ver logs en tiempo real
journalctl --user -u deepseek-proxy -f

# Reiniciar servicio
systemctl --user restart deepseek-proxy

# Ver estad√≠sticas de cach√©
curl http://localhost:7777/v1/cache/stats
```

## üìù Licencia

MIT
