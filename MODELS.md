# L√≠mites de Contexto de Modelos

## Modelos DeepSeek API

### DeepSeek Chat

- **Contexto m√°ximo**: 128,000 tokens
- **Generaci√≥n m√°xima**: 8,000 tokens
- **Caracter√≠sticas**: Modelo general de chat

### DeepSeek Reasoner

- **Contexto m√°ximo**: 128,000 tokens
- **Generaci√≥n m√°xima**: 64,000 tokens
- **Caracter√≠sticas**: Modelo de razonamiento mejorado

## Modelos con Visi√≥n

### üñºÔ∏è Visi√≥n Unificada con Gemini

 **Todos los modelos** ahora usan **Gemini 2.5 Flash Lite** para an√°lisis de im√°genes:

- **Procesamiento universal**: Cualquier modelo que pase por el proxy tiene visi√≥n habilitada
- **An√°lisis de im√°genes**: Procesado por Gemini (hasta 10MB por imagen)
- **Cach√© contextual**: Hash SHA-256 para evitar llamadas repetidas
- **Prompt adaptativo**: Se ajusta al contexto de la pregunta del usuario

### üîÑ Enrutamiento Inteligente

El proxy detecta autom√°ticamente el destino basado en el modelo solicitado:

```typescript
// Ejemplo de enrutamiento:
"vision-dsk-chat"     ‚Üí DeepSeek API (con visi√≥n Gemini)
"vision-dsk-reasoner" ‚Üí DeepSeek API (con visi√≥n Gemini)
```

### üìä Modelos Disponibles en el Proxy

El proxy expone **8 modelos** con visi√≥n:

| Tipo                  | Modelos Proxy                                     | Modelo Destino      | Contexto | Output | Visi√≥n |
| --------------------- | ------------------------------------------------- | ------------------- | -------- | ------ | ------ |
| **DeepSeek Chat**     | `vision-dsk-chat`, `deepseek-vision-chat`         | `deepseek-chat`     | 128K     | 8K     | ‚úÖ     |
| **DeepSeek Reasoner** | `vision-dsk-reasoner`, `deepseek-vision-reasoner` | `deepseek-reasoner` | 128K     | 64K    | ‚úÖ     |

### Para DeepSeek Chat:

```json
{
  "context": 100000,
  "output": 8000,
  "cost": {
    "input": 0.27,
    "output": 1.1
  }
}
```

### Para DeepSeek Reasoner:

```json
{
  "context": 100000,
  "output": 64000,
  "cost": {
    "input": 0.55,
    "output": 2.19
  }
}
```
